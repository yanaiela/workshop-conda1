- abstract: Chinese large language models (LLMs) demonstrate impressive performance
    on NLP tasks, particularly on discipline knowledge benchmarks, where certain Chinese
    LLMs are very competitive to GPT-4. Previous research has viewed these advancements
    as potential outcomes of data contamination or leakage, prompting efforts to create
    new detection methods and address evaluation issues in LLM benchmarks. However,
    there has been a lack of comprehensive assessment of the evolution of Chinese
    LLMs. To bridge this gap, this paper offers a thorough investigation of Chinese
    LLMs on discipline knowledge evaluation, delving into the advancements of various
    LLMs, including a group of related models and others. Specifically, we have conducted
    six assessments ranging from knowledge memorization to comprehension for robustness,
    encompassing tasks like predicting incomplete questions and options, identifying
    behaviors by the contaminational fine-tuning, and answering rephrased questions.
    Experimental findings indicate a positive correlation between the release time
    of LLMs and their memorization capabilities, but they struggle with variations
    in original question-options pairs. Additionally, our findings suggest that question
    descriptions have a more significant impact on the performance of LLMs.
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: liuc\_09@tju.edu.cn
    first_name: Chuang
    institution: Tianjin University
    last_name: Liu
    name: Chuang Liu
    semantic_scholar_id: https://www.semanticscholar.org/author/Chuang-Liu/2116348128
    username: ~Chuang_Liu3
  - dblp_id: https://dblp.org/pid/329/4176
    emails: cordercorder@qq.com
    first_name: Renren
    google_scholar_id: https://scholar.google.com/citations?user=qW3oQDUAAAAJ&hl=en
    last_name: Jin
    name: Renren Jin
    semantic_scholar_id: https://www.semanticscholar.org/author/Renren-Jin/2184143149
    username: ~Renren_Jin1
  - dblp_id: https://dblp.org/pid/s/MarkSteedman
    emails: steedman@inf.ed.ac.uk
    first_name: Mark
    google_scholar_id: https://scholar.google.com/citations?user=ccCd0_YAAAAJ&hl=en&oi=ao
    homepage: https://homepages.inf.ed.ac.uk/steedman/
    institution: University of Edinburgh
    last_name: Steedman
    name: Mark Steedman
    semantic_scholar_id: https://www.semanticscholar.org/author/Mark-Steedman/145332819
    username: ~Mark_Steedman1
  - dblp_id: https://dblp.org/pid/55/6548
    emails: dyxiong@tju.edu.cn
    first_name: Deyi
    google_scholar_id: https://scholar.google.com/citations?user=QPLO3myO5PkC&hl=en
    homepage: https://dyxiong.github.io
    institution: Tianjin University
    last_name: Xiong
    name: Deyi Xiong
    orcid: https://orcid.org/0000-0002-2353-5038
    semantic_scholar_id: https://www.semanticscholar.org/author/Deyi-Xiong/2694222
    username: ~Deyi_Xiong2
  decision: '2024'
  file: 3.pdf
  id: 3
  openreview_id: u9tX3hbV2z
  pdf_file: ba7f5ec796a0a4d2e279c9f3efa9157304472616.pdf
  title: Evaluating Chinese Large Language Models on Discipline Knowledge Acquisition
    via Assessing Memorization and Robustness
- abstract: Test contamination is a serious problem for the evaluation of large language
    models (LLMs)  because it leads to the overestimation of their performance and
    a quick saturation of benchmarks, even before the actual capability is achieved.
    One strategy to address this issue is the (adversarial) generation of variations,
    by including different exemplars and different rephrasings of the questions. However,
    these two interventions can lead to instances that can be more difficult (accumulating
    on the expected loss of performance by partly removing the contamination) but
    also to instances that can be less difficult (cancelling the expected loss of
    performance), which would make contamination undetectable. Understanding these
    two phenomena in terms of instance difficulty is critical to determine and measure
    contamination. In this paper we conduct a comprehensive analysis of these two
    interventions on an addition task with fine-tuned LLAMA-2 models.
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: bmehrba@upv.es
    first_name: Behzad
    google_scholar_id: https://scholar.google.com/citations?user=eG4fbvoAAAAJ&hl=en
    institution: Universidad Politécnica de Valencia
    last_name: Mehrbakhsh
    name: Behzad Mehrbakhsh
    username: ~Behzad_Mehrbakhsh1
  - dblp_id: https://dblp.org/pid/178/8272.html
    emails: dario.g.professional@gmail.com
    first_name: Dario
    google_scholar_id: https://scholar.google.com/citations?hl=en&user=eVutJvEAAAAJ
    homepage: https://dariogarigliotti.github.io/
    institution: University of Bergen
    last_name: Garigliotti
    name: Dario Garigliotti
    orcid: https://orcid.org/0000-0002-0331-000X
    semantic_scholar_id: https://www.semanticscholar.org/author/Dar%C3%ADo-Garigliotti/3359600
    username: ~Dario_Garigliotti1
  - dblp_id: https://dblp.org/pers/hd/m/Mart=iacute=nez=Plumed:Fernando
    emails: fmartinez@dsic.upv.es
    first_name: Fernando
    google_scholar_id: https://scholar.google.es/citations?user=a5qlaGIAAAAJ&hl=en
    homepage: https://nandomp.github.io/
    institution: Universitat Politècnica de València
    last_name: Martínez-Plumed
    name: Fernando Martínez-Plumed
    orcid: https://orcid.org/0000-0003-2902-6477
    username: ~Fernando_Martínez-Plumed1
  - dblp_id: https://dblp.org/pid/h/JoseHernandezOrallo
    emails: jorallo@upv.es
    first_name: Jose
    google_scholar_id: https://scholar.google.com/citations?user=n9AWbcAAAAAJ&hl=en
    homepage: http://josephorallo.webs.upv.es/
    institution: Universitat Politecnica de Valencia
    last_name: Hernandez-Orallo
    name: Jose Hernandez-Orallo
    username: ~Jose_Hernandez-Orallo1
  decision: '2024'
  file: 10.pdf
  id: 10
  openreview_id: gEtTo2DOOy
  pdf_file: 6604550990c801d65d2afef80f6701de91a25416.pdf
  title: Confounders in Instance Variation for the Analysis of Data Contamination
- abstract: Large language models pretrained on extensive web corpora demonstrate
    remarkable performance across a wide range of downstream tasks. However, a growing
    concern is data contamination, where evaluation datasets may be contained in the
    pretraining corpus, inflating model performance. Decontamination, the process
    of detecting and removing such data, is a potential solution; yet these contaminants
    may originate from altered versions of the test set, evading detection during
    decontamination. How different types of contamination impact the performance of
    language models on downstream tasks is not fully understood. We present a taxonomy
    that categorizes the various types of contamination encountered by LLMs during
    the pretraining phase and identify which types pose the highest risk.  We analyze
    the impact of contamination on two key NLP tasks---summarization and question
    answering---revealing how different types of contamination influence task performance
    during evaluation.
  attributes:
    paper_type: N/A
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: mpalaval@andrew.cmu.edu
    first_name: Medha
    last_name: Palavalli
    name: Medha Palavalli
    username: ~Medha_Palavalli1
  - dblp_id: https://dblp.org/pid/305/7615
    emails: abertsch@cs.cmu.edu
    first_name: Amanda
    google_scholar_id: https://scholar.google.com/citations?user=G1Jw4CYAAAAJ
    homepage: https://www.cs.cmu.edu/~abertsch/
    institution: Carnegie Mellon University
    last_name: Bertsch
    name: Amanda Bertsch
    orcid: https://orcid.org/0000-0002-1368-1111
    semantic_scholar_id: https://www.semanticscholar.org/author/Amanda-Bertsch/2138301112
    username: ~Amanda_Bertsch1
  - dblp_id: https://dblp.org/pid/116/0475
    emails: mgormley@cs.cmu.edu
    first_name: Matthew
    google_scholar_id: https://scholar.google.com/citations?user=GU0SZmYAAAAJ&hl=en
    homepage: http://www.cs.cmu.edu/~mgormley/
    institution: Solventum and School of Computer Science, Carnegie Mellon University
    last_name: Gormley
    middle_name: R.
    name: Matthew R. Gormley
    semantic_scholar_id: https://www.semanticscholar.org/author/Matthew-R.-Gormley/1762110
    username: ~Matthew_R._Gormley1
  decision: '2024'
  file: 13.pdf
  id: 13
  openreview_id: gf4RoEqO50
  pdf_file: 06af719949c8ce6adb0dc248ab71f8bfef5fc456.pdf
  title: A Taxonomy for Data Contamination in Large Language Models